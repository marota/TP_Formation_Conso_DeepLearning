{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 Prévision de consommation avec réseau de neurones\n",
    "\n",
    "\n",
    "<img src=\"pictures/Présentation_FormationIA_TPDeepLearning.png\" width=1000 height=60>\n",
    "\n",
    "**Dans l'épisode précédent**  \n",
    "\n",
    "Nos modèles de régression du TP1 nous ont donné des premiers résultats et des premières intuitions sur notre problème de prévision de consommation pour le lendemain. \n",
    "\n",
    "Nous avons pu analyser des profils de courbe de consommation au jour, à la semaine, au mois. Nous avons également observé la dépendance entre la consommation et la consommation retardée. Nous avons aussi vu l'impact des jours fériés. \n",
    "\n",
    "Nous avons ensuite utilisé de premiers modèles en machine learning pour apprendre par observations l'influence de différents contextes sur la consommation sans les décrires explicitement selon des lois. Nous sommes arrivés à une erreur moyenne de test de 2,8%, bien mieux que ce qui avait été obtenu via une approche naïve.\n",
    "\n",
    "Des difficultés se sont posées pour intégrer les variables météorologiques très dépendantes entre elles et pour intégrer un vecteur de consommation retardée.\n",
    "\n",
    "Avec l'approche classique exposée dans ce TP1, nous avons en particulier constaté le besoin d'une expertise et d'un travail autour des variables explicatives pour obtenir un modèle performant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aujourd'hui** \n",
    "\n",
    "Nous allons de nouveau nous attaquer à ce sujet de la prévision de consommation nationale pour le lendemain, mais cette fois en utilisant un modèle de prévision par réseau de neurones. Nous allons exploiter leur capacité à capter ces phénomènes non-linéaires et interdépendants. Nous allons mettre en évidence le moindre besoin en feature engineering en travaillant directement à la granularité de la donnée, sans créer de variables agrégées ou transformées par de l'expertise.\n",
    "\n",
    "**Ce que vous allez voir dans ce second TP**\n",
    "\n",
    "- Un rappel de notre problème et récapitulatif des performances de nos modèles précédents\n",
    "- Une nouvelle méthode numérique pour préparer ses données et faciliter l'apprentissage : la normalisation\n",
    "- La création d'un premier réseau de neurones pour prédire la consommation dans 24h\n",
    "- L'utilisation de tensorboard pour observer en temps réel la courbe d'apprentissage du réseau de neurones\n",
    "- La création de modèles de plus en plus performants en intégrant davantage d'informations dans notre modélisation\n",
    "- L'évaluation des modèles sur 2 types de jeux de test\n",
    "\n",
    "**Ce que vous allez devoir faire**\n",
    "\n",
    "- Compléter les quelques trous de codes que nous vous avons laissé si vous le souhaitez. La solution est disponible dans le TP complété.\n",
    "- Répondre aux quelques questions disséminées dans ce TP\n",
    "- Entrainer votre propre modèle pour améliorer les performances d'un modèle existant et essayer de remporter notre mini-challenge !\n",
    "\n",
    "__NB__ : Pour ce TP nous utiliserons Keras, une bibliothèque python de haut niveau qui appelle des fonctions de la librairie TensorFlow. D'autres librairies existent, Keras a été retenue en raison de sa facilité d'utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionnement en temps\n",
    "La durée estimée de ce TP est d'environ 1h30 :\n",
    "- 10 minutes pour charger les données pour les réseaux de neurones \n",
    "- 20 minutes pour entrainer un premier modèle de réseau de neurones, en examiner le code implémentant ce réseau de neurones\n",
    "- Le reste pour jouer et tenter d'améliorer la qualité de la prédiction avec de nouvelles variables explicatives, ou en choisissant d'autres hyper-paramètres. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import zipfile\n",
    "import math\n",
    "from time import time\n",
    "import joblib\n",
    "\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "# sklearn est la librairie de machine learning en python et scipy une librairie statistiques\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Keras est la librairie que nous utilisons pour se créer des modèles de réseau de neurones\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "from IPython.display import SVG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Récupération et préparation des données\n",
    "\n",
    "Dans cette partie nous allons charger les fichiers csv nécessaires pour l'analyse, puis les convertir en data-frame python. Les données de base à récupérer sont :\n",
    "- la base de données issues du TP1 (Les historiques de consommation, leur lag, les données météo en température, leur lag, les jours feriés) \n",
    "\n",
    "En terme de transformation des données pour mieux les préparer:\n",
    "\n",
    "- nous allons aussi voir comment normaliser les données, une transformation souvent bien utile en pratique pour une meilleure convergence numérique. \n",
    "\n",
    "Cela vient compléter les transformations vu précédemment pour les données calendaires, et aussi la transformation \"one-hot\" pour les données catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choix du répertoire de travail \"data_folder\" dans lequel toutes les fichiers csv seront entreposés\n",
    "# a actualiser avec le repertoire par defaut sur le serveur\n",
    "data_folder = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "## Petite vérification\n",
    "print(\"Mon repertoire est : {}\".format(data_folder))\n",
    "print(\"Fichiers contenus dans ce répertoire :\")\n",
    "for file in os.listdir(data_folder):\n",
    "    print(\" - \" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération de nos variables à prédire: la consommation française"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_conso_csv = os.path.join(data_folder, \"y_conso_nat_full.csv\")\n",
    "Y = pd.read_csv(y_conso_csv, sep=\",\", engine='c', header=0)\n",
    "Y.rename(columns={\"y\": \"conso_nat_realisee\"}, inplace=True)\n",
    "Y['ds'] = pd.to_datetime(Y['ds'])\n",
    "Y['ds'] = Y['ds'].dt.tz_localize(None)\n",
    "display(Y.head(5))\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Petit rappel, que fait la fonction \"shape\" ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données météo sont confidentielles, et donc ont été cryptées. Pour les lire vous avez besoin d'un mot de passe qui ne peut vous être donné que dans le cadre d'un travail au sein de RTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des températures et jours fériés\n",
    "Xinput_zip = os.path.join(data_folder, \"x_input_full.zip\")\n",
    "zfXinput = zipfile.ZipFile(Xinput_zip)\n",
    "zfXinput.setpassword(bytes(password,'utf-8'))\n",
    "X = pd.read_csv(zfXinput.open('x_input_full.csv'), sep=\",\", engine='c', header=0)\n",
    "X['ds'] = pd.to_datetime(X['ds'])\n",
    "X['ds'] = X['ds'].dt.tz_localize(None)\n",
    "\n",
    "display(X.head(5))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**Prenons quelques instants pour comprendre ces histoires de variables retardées.**\n",
    "\n",
    "Imaginons que l'on veuille prédire la consommation nationale pour le point horaire cible du 09/01/2014 à 00h00 (ligne 24 de working_df)\n",
    "\n",
    "Utiliser dans un modèle de prédiction :\n",
    "* la consommation réalisée de la veille (08/01/2014 à 00h00)\n",
    "* les infos de météo réalisée de la veille\n",
    "* les **prévisions** météo du point horaire cible (09/01/2014 à 00h00)\n",
    "\n",
    "semble être pertinent.\n",
    "\n",
    "</font>\n",
    "<br/>\n",
    "  \n",
    "<font color='green'>\n",
    "\n",
    "* Est-ce que le shift a été fait dans le bon sens ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère aussi le scaler qui permet de dénormaliser la prédiction du réseau de neurones\n",
    "scaler_conso_nat = joblib.load(os.path.join(data_folder, \"scaler_conso_nat.save\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**A propos de la normalisation...**\n",
    "\n",
    "\n",
    "</font>\n",
    "\n",
    "En théorie, la normalisation des données d'entrée n'est pas indispensable pour entrainer un réseau de neurones.  \n",
    "\n",
    "En effet, on devrait apprendre des poids et biais plus ou moins importants pour équilibrer les contributions des différentes variables explicatives en entrée. \n",
    "\n",
    "Cependant en pratique, normaliser les données d'entrée permet généralement d'obtenir un apprentissage plus rapide du réseau de neurones.\n",
    "\n",
    "<br/>\n",
    "<font color='green'>\n",
    "    \n",
    "* Comment l'expliquez-vous ?\n",
    "\n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Création des jeux d'apprentissage, de validation, et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "    \n",
    "**Question** : \n",
    "* A quoi servent les jeux d'entrainement, de validation, et de test ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous créer les jeux de données suivants :\n",
    "* Jeu d'entrainement : 90% des points pris aléatoirement entre le début du dataset et le 31 décembre 2017\n",
    "* Jeu de validation : les 10% restant des points entre le début du dataset et le 31 décembre 2017\n",
    "* Jeu de test : tous les points horaires à partir du 1er janvier 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D'abord on repère les lignes de chacun des set\n",
    "\n",
    "TEST_START_DATE = datetime.datetime(year=2018, month=1, day=1)\n",
    "\n",
    "mask_test_set = (X[\"ds\"] >= TEST_START_DATE)\n",
    "\n",
    "mask_train_validation = (X['ds'] < TEST_START_DATE)\n",
    "mask_train_validation = mask_train_validation.astype(bool)\n",
    "\n",
    "def filter(x, threshold):\n",
    "    return True if x < threshold else False\n",
    "    \n",
    "mask_train_set = [filter(x, 0.9) for x in np.random.uniform(0, 1, size=X.shape[0])] & mask_train_validation\n",
    "mask_validation_set = ~mask_train_set & mask_train_validation\n",
    "\n",
    "# petite verif\n",
    "print(X.shape)\n",
    "print(np.sum(mask_train_set))\n",
    "print(np.sum(mask_validation_set))\n",
    "print(np.sum(mask_test_set))\n",
    "print(np.sum(mask_train_set) + np.sum(mask_validation_set) + np.sum(mask_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puis on constitue les sets\n",
    "\n",
    "X_train_full = X[mask_train_set]\n",
    "X_validation_full = X[mask_validation_set]\n",
    "X_test_full = X[mask_test_set]\n",
    "\n",
    "Y_train_full = Y[mask_train_set]\n",
    "Y_validation_full = Y[mask_validation_set]\n",
    "Y_test_full = Y[mask_test_set]\n",
    "\n",
    "X_train_full.reset_index(inplace=True, drop=True)\n",
    "X_validation_full.reset_index(inplace=True, drop=True)\n",
    "X_test_full.reset_index(inplace=True, drop=True)\n",
    "Y_train_full.reset_index(inplace=True, drop=True)\n",
    "Y_validation_full.reset_index(inplace=True, drop=True)\n",
    "Y_test_full.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape de X_train_full : \" + str(X_train_full.shape))\n",
    "print(\"Shape de X_validation_full : \" + str(X_validation_full.shape))\n",
    "print(\"Shape de X_test_full : \" + str(X_test_full.shape))\n",
    "print(\"Shape de Y_train : \" + str(Y_train_full.shape))\n",
    "print(\"Shape de Y_validation : \" + str(Y_validation_full.shape))\n",
    "print(\"Shape de Y_test : \" + str(Y_test_full.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Getting started with Keras\n",
    "\n",
    "Jusqu'ici, nous avons importé nos données. Nous les avons ensuite préparées pour les fournir au réseau de neurones (one-hot encoding, normalisation). Nous avons également créé nos jeux d'entrainement, validation, et de test.\n",
    "\n",
    "Il est maintenant l'heure de se construire un réseau de neurones, de l'entrainer, et de lui faire faire des prédictions !\n",
    "\n",
    "Dans cette partie III) nous allons nous familiariser avec la librairie Keras qui permet d'implémenter des réseaux de neurones, puis en partie IV) nous l'appliquerons à notre problématique de prévision de consommation.\n",
    "\n",
    "**Cette partie III) est générique et indépendante de notre problématique de prévision de consommation**\n",
    "\n",
    "<img src=\"pictures/FirstNeuralNetwork.jpeg\" width=700 height=60>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deux fonctions bien utiles\n",
    "\n",
    "Nous allons commencer par implémenter deux fonctions que nous appellerons pour chacun des modèles que nous allons tester:\n",
    "- Fonction 1: **new_keras_model**, pour instancier un modèle de réseau de neurone avant apprentissage\n",
    "- Fonction 2: **plot_neural_net**, pour visualiser un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une architecture de réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_keras_model(n_inputs, n_outputs=1, hidden_layers=None):\n",
    "    \"\"\"      \n",
    "    arguments\n",
    "        - n_inputs : le nombre de features en entrée\n",
    "        - n_outputs : le nombre de sorties (variables à prédire)\n",
    "        - hidden_layers : une liste. \n",
    "                          La taille de la liste donne le nombre de couches cachées.\n",
    "                          Les éléments de la liste donnent le nombre de neurones par couche.\n",
    "                          Cette liste doit contenir au moins un élément\n",
    "        \n",
    "    returns\n",
    "        - un objet de type Model \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(hidden_layers == None):\n",
    "        hidden_layers = [n_inputs, n_inputs]\n",
    "        \n",
    "    nb_hidden_layers = len(hidden_layers)\n",
    "    \n",
    "    model.add(Dense(hidden_layers[0], input_dim=n_inputs, activation='relu'))\n",
    "    for l in range(nb_hidden_layers - 1):\n",
    "        model.add(Dense(hidden_layers[l + 1], activation='relu'))\n",
    "\n",
    "    # Pour une régression, la fonction d'activation finale est simplement la fonction identité\n",
    "    model.add(Dense(n_outputs, activation='linear'))  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection de l'architecture d'un reseau de neurones\n",
    "On se créé un réseau avec un certains nombre de couches qui peuvent chacune avoir différentes dimensions. On peut ensuite inspecter les dimensions et le nombre de paramètres de ce réseau avec la méthode _summary_ de Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on se crée un réseau de neurones avec un certains nombre d'entrées et sorties\n",
    "n_inputs = 8  #un choix raisonnable pour visualiser ce modèle ensuite\n",
    "n_outputs = 1\n",
    "\n",
    "hidden_layers = [10, n_inputs, 6]\n",
    "dummy_model = new_keras_model(n_inputs, n_outputs, hidden_layers=hidden_layers)\n",
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons-nous maintenant une fonction pour dessiner ce réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run auxiliairyMethodsTP2.py  #on charge un fichier où sont définies nos fonctions auxilaires non détaillées dans ce TP\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "\n",
    "def plot_neural_net(model):\n",
    "    layers = [model.input_shape[1]]\n",
    "    for layer in model.layers:\n",
    "        layers.append(layer.get_output_at(0).get_shape().as_list()[1])\n",
    "\n",
    "    plotNeuralNet(layers)\n",
    "    (graph,) = pydot.graph_from_dot_file('out.dot')\n",
    "    \n",
    "    fileNameImage = 'yourNeuralNet.png'\n",
    "    graph.write_png(fileNameImage, prog='dot')\n",
    "    img = Image(fileNameImage)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons le reseau de neurone test créé précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neural_net(dummy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTENTION: Pour des grandes tailles de reseau, cette visualisation n'est pas adaptée et le temps d'éxécution de cette fonction sera très long !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "    \n",
    "**Défi !** : \n",
    "* Créez vous un reseau de neurones en forme de noeud papillon, dont la couche de sortie fait la même dimension que la couche d'entrée.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre new_keras_model à créer ici\n",
    "model_noeud_papillon = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_neural_net(model_noeud_papillon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravo ! Vous venez de créer un réseau de neurone d'une classe très particulière: c'est un autoencoder !\n",
    "Pour les curieux, vous pouvez retrouver le bestiaire des réseaux de neurones ici: https://rte-france.knowledgeplaza.net/tile/view/47639/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV) Un premier modèle de réseau de neurones : variables calendaires + lag conso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des variables explicatives\n",
    "\n",
    "pour ce TP, nous avons un jeu d'entrée X contenant beaucoup de variables. Afin de commencer par un modèle simple, nous allons élaguer ce X pour réduire le nombre de features en entrée. Dans ce TP, nous allons donc lister les colonnes à retirer des datasets X initialisés ci-dessus.\n",
    "\n",
    "Pour un cas d'étude réel, une approche pragmatique serait de commencer par se créer un premier X simple, de voir les performances du modèle, puis ensuite d'incorporer de plus en plus de features dans le X pour évaluer la progression des performances de nos modèles.\n",
    "\n",
    "Toutefois, en deep learning, il est courant commencer directement en mettant en entrée toute l'information disponible. En effet une des forces des réseaux de neurones est leur capacité à \"digérer\" la donnée, en se nourrissant d'informations redondantes.\n",
    "\n",
    "pour des raisons pédagogiques, nous allons commencer avec la première approche.\n",
    "\n",
    "Pour le premier réseau de neurones que nous allons entrainer, nous allons simplement garder les variables calendaires ainsi que la valeur de consommation nationale réalisée la veille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Petit rappel pour se remettre en mémoire les variables que nous avons à disposition\n",
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sélectionnons un sous-ensemble de ces variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols_to_keep = ['conso_nat_realisee_scaled_lag1D'] \\\n",
    "+ [\"month_\" + str(x) for x in range(1, 13)] \\\n",
    "+ [\"hour_\" + str(x) for x in range(0, 24)] \\\n",
    "+ [\"weekday\"]\n",
    "\n",
    "y_cols_to_keep = [\"conso_nat_realisee_scaled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On restreint nos jeux d'entrainement et de tests à ces variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_full[x_cols_to_keep]\n",
    "X_validation = X_validation_full[x_cols_to_keep]\n",
    "X_test = X_test_full[x_cols_to_keep]\n",
    "\n",
    "Y_train = Y_train_full[y_cols_to_keep]\n",
    "Y_validation = Y_validation_full[y_cols_to_keep]\n",
    "Y_test = Y_test_full[y_cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après élagage des variables\n",
    "print(X_train.columns)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du réseau de neurones et hyper-paramétrage\n",
    "Un réseau de neurones profond est constuitué d'un certains nombre de couches, chacune portant un certain nombre de neurones. Ce sont 2 hyperparamètres que vous pouvez faire varier et qui vous permettront d'obtenir un apprentissage plus ou moins précis, en utilisant plus ou moins de puissance de calcul.\n",
    "\n",
    "Le \"learning rate\" de l'optimiseur est également un hyperparamètre qui influencera la convergence et la vitesse de convergence de l'apprentissage, où l'on cherche à optimiser notre modèle pour minimiser l'erreur de prédiction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]  #nombre de features en entrée du réseau de neurones\n",
    "n_outputs = 1\n",
    "hidden_layers = [n_inputs, n_inputs, n_inputs, n_inputs, n_inputs]\n",
    "\n",
    "first_model = new_keras_model(n_inputs, n_outputs, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# on affiche le nombre de paramètres de ce modèle avec la fonction summary de Keras\n",
    "first_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=Adam(lr=0.01), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée ici une instance de l'utilitaire tensorboard qui va nous permettre de visualiser \n",
    "# les courbes d'apprentissage de nos différents modèles.\n",
    "# On reviendra avec plus d'explication sur TensorBoard un peu plus tard.\n",
    "# Donner un nom a votre modele pour le retrouver dans les logs tensorboard\n",
    "model_name = \"my_first_model_\" + datetime.datetime.now().strftime(\"%H-%M-%S\")\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "La cellule suivante peut prendre un peu de temps à s'exécuter. On reconnait là la méthode **fit** commune à chaque modèle de machine-learning pour entraîner son modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres d'appel\n",
    "# - epoch: on précise le nombre d'epochs (le nombre de fois que l'on voit le jeu d'apprentissage en entier)\n",
    "# - batch size: le nombre d'exemples sur lequel on fait un \"pas\" d'apprentissage parmi tout le jeu\n",
    "# - validation_split: la proportion d'exemples que l'on conserve pour notre jeu de validation\n",
    "# - callbacks: pour appeler des utilitaires/fonctions externes pour récupérer des résultats\n",
    "first_model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=100, \n",
    "    batch_size=100, \n",
    "    validation_data=(X_validation, Y_validation),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* D'après les informations de logs exposées ici, quelle semble être la perfomance atteinte par votre réseau de neurones ? \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "c'est un utilitaire de tensorflow qui permet de visualiser en temps réel les courbes d'apprentissage des réseau de neurones et est donc utile pour arrêter l'apprentissage si les progrès sont faibles.\n",
    "\n",
    "En particulier, vous pouvez vous intéresser à la courbe de l'erreur (loss) d'entrainement et de validation pour visualiser la progression de l'apprentissage et une tendance au surapprentissage en fin d'apprentissage.\n",
    "\n",
    "<img src=\"pictures/CourbesTensorboard.png\" width=1000 height=60>\n",
    "\n",
    "**Pour ouvrir une fenêtre tensorboard, revenez sur la page d'accueil de Jupyter, placez vous dans le dossier logs dans lequel se trouve les logs de vos entrainement, puis cliquez sur New (en haut à droite) et enfin sur Tensorboard**.\n",
    "\n",
    "Une fenêtre pop-up doit s'ouvrir. Si elle est bloquée, autorisez son ouverture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Vous devriez visualiser les courbes de 2 modèles: celui que vous venez d'entrainer et un modèle qui avait été entrainé de la même manière mais avec des données non normalisée. Que constatez-vous ? Comment l'expliquez-vous ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la qualité du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_scaled = first_model.predict(X_train).reshape(-1)\n",
    "predictions_val_scaled = first_model.predict(X_validation).reshape(-1)\n",
    "predictions_test_scaled = first_model.predict(X_test).reshape(-1)\n",
    "\n",
    "predictions_train = scaler_conso_nat.inverse_transform(predictions_train_scaled)\n",
    "predictions_val = scaler_conso_nat.inverse_transform(predictions_val_scaled)\n",
    "predictions_test = scaler_conso_nat.inverse_transform(predictions_test_scaled)\n",
    "\n",
    "print(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error_on_train = np.abs((Y_train_full['conso_nat_realisee'] - predictions_train) / Y_train_full['conso_nat_realisee'])\n",
    "mean_error_on_train = np.mean(relative_error_on_train)\n",
    "max_error_on_train = np.max(relative_error_on_train)\n",
    "rmse = np.sqrt(mean_squared_error(Y_train_full['conso_nat_realisee'], predictions_train))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de train : \" + str(mean_error_on_train * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de train : \" + str(max_error_on_train * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error_on_val = np.abs((Y_validation_full['conso_nat_realisee'] - predictions_val) / Y_validation_full['conso_nat_realisee'])\n",
    "mean_error_on_val = np.mean(relative_error_on_val)\n",
    "max_error_on_val = np.max(relative_error_on_val)\n",
    "rmse = np.sqrt(mean_squared_error(Y_validation_full['conso_nat_realisee'], predictions_val))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de test : \" + str(mean_error_on_val * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de test : \" + str(max_error_on_val * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error_on_test = np.abs((Y_test_full['conso_nat_realisee'] - predictions_test) / Y_test_full['conso_nat_realisee'])\n",
    "mean_error_on_test = np.mean(relative_error_on_test)\n",
    "max_error_on_test = np.max(relative_error_on_test)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_full['conso_nat_realisee'], predictions_test))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de test : \" + str(mean_error_on_test * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de test : \" + str(max_error_on_test * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test_full['ds'], Y_test_full['conso_nat_realisee'], 'b')\n",
    "plt.plot(Y_test_full['ds'], predictions_test, 'r')\n",
    "\n",
    "plt.title(\"Evaluation de l'erreur sur le jeu de test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur est ici comparable à celle des autres modèles en machine Learning (random forest, xgboost). Cela peut nous conforter dans le fait que notre réseau de neurones s'est créé de bonnes représentations pour ces variables calendaires. \n",
    "\n",
    "La différence en performance peut devenir plus flagrante lorsque l'on intègre des variables à une maille très granulaire (les pixels d'une images, la température dans toutes les villes de France) avec une forte interdépendance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour inspecter dynamiquement des visualisations, la librairie plotly se révèle très utile.\n",
    "Ci-dessous vous pouvez identifier les jours et heures qui présentent les erreurs les plus importantes pour ensuite imaginer ce qui a pu pêcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot, iplot_mpl\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "iplot([{\"x\": Y_test_full['ds'], \"y\": relative_error_on_test}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Quelles sont les heures ou les journées avec les erreurs les plus importantes. Avez-vous une idée à quoi pourrait correspondre ces heures ou ces jours ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V) A vous de jouer, faites fonctionner vos neurones naturels\n",
    "\n",
    "Il peut y avoir différents objectifs de performance selon le besoin. En général on cherche un compromis entre la précision du modèle et la puissance de calcul nécessaire pour entraîner et faire tourner ce modèle.\n",
    "\n",
    "Nous décernerons 2 récompenses!\n",
    "\n",
    "- Défi 1: le modèle le plus précis.\n",
    "- Défi 2: le modèle le plus frugal moyennant une perte de précision.\n",
    "Les critères sont encore à affiner ensemble!\n",
    "\n",
    "<img src=\"pictures/we-need-you.png\" width=500 height=60>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Challenge**: entrainez et testez votre nouveau modèle avec de nouvelles variables et paramètres choisies\n",
    "\n",
    "N'hésitez pas à vous inspirer par le code ci-dessus ;-)\n",
    "venez partager vos investigations sur cette google sheet : https://docs.google.com/spreadsheets/d/1oIx8jjzIh7Ugp3ZJMCOEwns6KCJxo4ua_jW5hIvjjFI/edit?usp=sharing\n",
    "\n",
    "Quelques idées si vous n'êtes pas inspirés :\n",
    "- essayer d'autres hyperparamètres (learning rate, taille des minibatch, nombre de couches...)\n",
    "- regarder ce qu'il se passe si on utilise des variables non normalisées\n",
    "- ajouter d'autres variables en entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Votre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappel des variables explicatives à disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialement\n",
    "X_train_full.columns.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sélectionne les variables que l'on souhaite conserver en précisant simplement à quelle catégorie elles appartiennent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#TO DO\n",
    "x_cols_to_keep = ['conso_nat_realisee_scaled_lag1D'] \\\n",
    "+ [\"month_\" + str(x) for x in range(1, 13)] \\\n",
    "+ [\"hour_\" + str(x) for x in range(0, 24)] \\\n",
    "+ [\"weekday\"]\n",
    "\n",
    "y_cols_to_keep = [\"conso_nat_realisee_scaled\"]  # <= pas la peine d'y toucher\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_full[x_cols_to_keep]\n",
    "X_validation = X_validation_full[x_cols_to_keep]\n",
    "X_test = X_test_full[x_cols_to_keep]\n",
    "\n",
    "Y_train = Y_train_full[y_cols_to_keep]\n",
    "Y_validation = Y_validation_full[y_cols_to_keep]\n",
    "Y_test = Y_test_full[y_cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après élagage des variables\n",
    "print(X_train.columns)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du réseau de neurones, hyper-paramétrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez jouer sur l'architecture de votre reseau de neurones ici en précisant le nombre de couches et la taille des couches dans le vecteur hiddenLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]  # nombre d'entrées du modèle\n",
    "n_outputs = 1\n",
    "\n",
    "## votre choix !\n",
    "hidden_layers = [n_inputs, n_inputs, n_inputs, n_inputs, n_inputs]\n",
    "##\n",
    "\n",
    "mon_reseau_de_neurones = new_keras_model(n_inputs, n_outputs, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on affiche le nombre de paramètres de votre modèle avec la fonction summary de Keras\n",
    "mon_reseau_de_neurones.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_reseau_de_neurones.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=Adam(lr=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "Notre utilitaire de tensorflow qui permet de visualiser en temps réel les courbes d'apprentissage des réseau de neurones et est donc utile pour arrêter l'apprentissage si les progrès sont faibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donner un nom a votre modele pour le retrouver dans les logs tensorboard\n",
    "model_name = \"my_own_model_\" + datetime.datetime.now().strftime(\"%H-%M-%S\")\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "La cellule suivante peut prendre un peu de temps à s'exécuter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_reseau_de_neurones.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=100, \n",
    "    batch_size=100, \n",
    "    validation_data=(X_validation, Y_validation),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la qualité du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_scaled = mon_reseau_de_neurones.predict(X_test).reshape(-1)\n",
    "predictions_test = scaler_conso_nat.inverse_transform(predictions_test_scaled)\n",
    "\n",
    "print(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test_full['ds'], Y_test_full['conso_nat_realisee'], 'b')\n",
    "plt.plot(Y_test_full['ds'], predictions_test, 'r')\n",
    "\n",
    "plt.title(\"Evaluation de l'erreur sur le jeu de test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error_on_train = np.abs((Y_train_full['conso_nat_realisee'] - predictions_train) / Y_train_full['conso_nat_realisee'])\n",
    "mean_error_on_train = np.mean(relative_error_on_train)\n",
    "max_error_on_train = np.max(relative_error_on_train)\n",
    "rmse = np.sqrt(mean_squared_error(Y_train_full['conso_nat_realisee'], predictions_train))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de train : \" + str(mean_error_on_train * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de train : \" + str(max_error_on_train * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error_on_val = np.abs((Y_validation_full['conso_nat_realisee'] - predictions_val) / Y_validation_full['conso_nat_realisee'])\n",
    "mean_error_on_val = np.mean(relative_error_on_val)\n",
    "max_error_on_val = np.max(relative_error_on_val)\n",
    "rmse = np.sqrt(mean_squared_error(Y_validation_full['conso_nat_realisee'], predictions_val))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de test : \" + str(mean_error_on_val * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de test : \" + str(max_error_on_val * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error_on_test = np.abs((Y_test_full['conso_nat_realisee'] - predictions_test) / Y_test_full['conso_nat_realisee'])\n",
    "\n",
    "mean_error_on_test = np.mean(relative_error_on_test)\n",
    "max_error_on_test = np.max(relative_error_on_test)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_full['conso_nat_realisee'], predictions_test))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de test : \" + str(mean_error_on_test * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de test : \" + str(max_error_on_test * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "iplot([{\"x\": Y_test_full['ds'], \"y\": relative_error_on_test}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour aller encore plus loin\n",
    "\n",
    "Le modèle ci-dessus peut être rendu encore plus performant par exemple en considérant des features comme \"jour d'avant vacances\", \"jour d'après vacances\"... \n",
    "\n",
    "Passer du temps à tuner les hyper-paramètres serait certainement bénéfique aussi.\n",
    "\n",
    "De manière assez surprenante, élargir le réseau de neurones pour prédire les consommations régionales peut également améliorer la qualité de la prédiction de l'échelle nationale. C'est l'idée du multi-tasking.\n",
    "\n",
    "On pourra également considérer en sortie du modèle non pas la prédiction pour juste 24 heures plus tard, mais plutôt pour une plage horaire  \n",
    "[1 heure plus tard, ..., 24 heures plus tard]. Ceci permet de capter des dynamiques.\n",
    "\n",
    "\n",
    "Des pistes:\n",
    "insérer le lag Jours_Feries_J-1\n",
    "voir si un intérêt à passer toutes les stations ou seulement la température France avec expertise sur importance des stations (en fait ça suffit avec les stations fournies!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple d apprentissage avec differentes variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici quelques exemples de courbes d'apprentissage. \n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "* Que pensez-vous de la courbe rose ?\n",
    "\n",
    "</font>\n",
    "\n",
    "<img src=\"pictures/ResultsApprentissages.png\" width=500 height=50>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
